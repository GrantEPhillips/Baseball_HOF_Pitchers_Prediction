{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseball hall of fame pitchers \n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grant Phillips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of historical hall of fame ballot results and various pitching statistics, can I predict whether a pitcher on the hall of fame ballot will be inducted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from   sklearn.ensemble           import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model    import LogisticRegression, RidgeClassifier, Lasso\n",
    "from sklearn.metrics         import f1_score, balanced_accuracy_score, confusion_matrix, average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from   sklearn.preprocessing      import *\n",
    "from   sklearn.base               import BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path where all data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data/baseballdatabank-master/core/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in two csv's with data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_df = pd.read_csv(PATH/\"HallOfFame.csv\")\n",
    "pitching_df = pd.read_csv(PATH/\"Pitching.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Scikit learn pipeline and deal with transformations that require target transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encode target (induction result) so the feature is not lost when we aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_df['inducted'] = OneHotEncoder().fit_transform(np.array(hof_df['inducted']).reshape(-1,1)).toarray()[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge dataframes to one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pitching_df.merge(hof_df, how='inner', on='playerID').drop_duplicates(subset=list(pitching_df.columns)[2:], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only include players (exclude managers, executives, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_players = data[data['category'] == 'Player']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get career statistics for each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_players.groupby('playerID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out players with little pitching experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pitchers = data_agg[data_agg['BFP'] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix target column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-cb8b8e68258e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pitchers['inducted'] = (np.array(data_pitchers['inducted']) > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "data_pitchers['inducted'] = (np.array(data_pitchers['inducted']) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>playerID</th>\n",
       "      <th>abbotji01</th>\n",
       "      <th>adamsba01</th>\n",
       "      <th>aguilri01</th>\n",
       "      <th>akerja01</th>\n",
       "      <th>alexado01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yearID_x</th>\n",
       "      <td>21932.000</td>\n",
       "      <td>36411.00</td>\n",
       "      <td>37863.000</td>\n",
       "      <td>27574.00</td>\n",
       "      <td>45552.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stint</th>\n",
       "      <td>12.000</td>\n",
       "      <td>19.00</td>\n",
       "      <td>22.000</td>\n",
       "      <td>17.00</td>\n",
       "      <td>27.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>87.000</td>\n",
       "      <td>194.00</td>\n",
       "      <td>86.000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>194.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>108.000</td>\n",
       "      <td>140.00</td>\n",
       "      <td>81.000</td>\n",
       "      <td>45.00</td>\n",
       "      <td>174.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>263.000</td>\n",
       "      <td>482.00</td>\n",
       "      <td>732.000</td>\n",
       "      <td>495.00</td>\n",
       "      <td>561.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>254.000</td>\n",
       "      <td>355.00</td>\n",
       "      <td>89.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>464.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>31.000</td>\n",
       "      <td>206.00</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHO</th>\n",
       "      <td>6.000</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>0.000</td>\n",
       "      <td>15.00</td>\n",
       "      <td>318.000</td>\n",
       "      <td>123.00</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPouts</th>\n",
       "      <td>5022.000</td>\n",
       "      <td>8986.00</td>\n",
       "      <td>3874.000</td>\n",
       "      <td>2238.00</td>\n",
       "      <td>10103.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>1779.000</td>\n",
       "      <td>2841.00</td>\n",
       "      <td>1233.000</td>\n",
       "      <td>679.00</td>\n",
       "      <td>3376.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER</th>\n",
       "      <td>791.000</td>\n",
       "      <td>917.00</td>\n",
       "      <td>512.000</td>\n",
       "      <td>272.00</td>\n",
       "      <td>1406.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>154.000</td>\n",
       "      <td>68.00</td>\n",
       "      <td>138.000</td>\n",
       "      <td>64.00</td>\n",
       "      <td>324.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>620.000</td>\n",
       "      <td>430.00</td>\n",
       "      <td>351.000</td>\n",
       "      <td>274.00</td>\n",
       "      <td>978.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>888.000</td>\n",
       "      <td>1036.00</td>\n",
       "      <td>1030.000</td>\n",
       "      <td>404.00</td>\n",
       "      <td>1528.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAOpp</th>\n",
       "      <td>3.084</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.628</td>\n",
       "      <td>3.55</td>\n",
       "      <td>6.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERA</th>\n",
       "      <td>49.460</td>\n",
       "      <td>70.94</td>\n",
       "      <td>66.430</td>\n",
       "      <td>53.96</td>\n",
       "      <td>88.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBB</th>\n",
       "      <td>30.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.000</td>\n",
       "      <td>68.00</td>\n",
       "      <td>60.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP</th>\n",
       "      <td>53.000</td>\n",
       "      <td>26.00</td>\n",
       "      <td>53.000</td>\n",
       "      <td>13.00</td>\n",
       "      <td>74.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HBP</th>\n",
       "      <td>32.000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>36.000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>53.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK</th>\n",
       "      <td>11.000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFP</th>\n",
       "      <td>7211.000</td>\n",
       "      <td>11947.00</td>\n",
       "      <td>5391.000</td>\n",
       "      <td>3144.00</td>\n",
       "      <td>14162.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>5.000</td>\n",
       "      <td>89.00</td>\n",
       "      <td>557.000</td>\n",
       "      <td>321.00</td>\n",
       "      <td>56.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>880.000</td>\n",
       "      <td>1129.00</td>\n",
       "      <td>568.000</td>\n",
       "      <td>312.00</td>\n",
       "      <td>1541.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH</th>\n",
       "      <td>70.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.000</td>\n",
       "      <td>32.00</td>\n",
       "      <td>116.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>47.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.000</td>\n",
       "      <td>12.00</td>\n",
       "      <td>97.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIDP</th>\n",
       "      <td>200.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.000</td>\n",
       "      <td>19.00</td>\n",
       "      <td>242.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearID_y</th>\n",
       "      <td>22055.000</td>\n",
       "      <td>37145.00</td>\n",
       "      <td>38114.000</td>\n",
       "      <td>27720.00</td>\n",
       "      <td>45885.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ballots</th>\n",
       "      <td>5676.000</td>\n",
       "      <td>4769.00</td>\n",
       "      <td>9880.000</td>\n",
       "      <td>5390.00</td>\n",
       "      <td>10580.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needed</th>\n",
       "      <td>4257.000</td>\n",
       "      <td>3591.00</td>\n",
       "      <td>7410.000</td>\n",
       "      <td>4046.00</td>\n",
       "      <td>7935.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votes</th>\n",
       "      <td>143.000</td>\n",
       "      <td>456.00</td>\n",
       "      <td>57.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inducted</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "playerID  abbotji01  adamsba01  aguilri01  akerja01  alexado01\n",
       "yearID_x  21932.000   36411.00  37863.000  27574.00  45552.000\n",
       "stint        12.000      19.00     22.000     17.00     27.000\n",
       "W            87.000     194.00     86.000     47.00    194.000\n",
       "L           108.000     140.00     81.000     45.00    174.000\n",
       "G           263.000     482.00    732.000    495.00    561.000\n",
       "GS          254.000     355.00     89.000      0.00    464.000\n",
       "CG           31.000     206.00     10.000      0.00     98.000\n",
       "SHO           6.000      44.00      0.000      0.00     18.000\n",
       "SV            0.000      15.00    318.000    123.00      3.000\n",
       "IPouts     5022.000    8986.00   3874.000   2238.00  10103.000\n",
       "H          1779.000    2841.00   1233.000    679.00   3376.000\n",
       "ER          791.000     917.00    512.000    272.00   1406.000\n",
       "HR          154.000      68.00    138.000     64.00    324.000\n",
       "BB          620.000     430.00    351.000    274.00    978.000\n",
       "SO          888.000    1036.00   1030.000    404.00   1528.000\n",
       "BAOpp         3.084       3.85      4.628      3.55      6.006\n",
       "ERA          49.460      70.94     66.430     53.96     88.660\n",
       "IBB          30.000       0.00     42.000     68.00     60.000\n",
       "WP           53.000      26.00     53.000     13.00     74.000\n",
       "HBP          32.000      47.00     36.000     40.00     53.000\n",
       "BK           11.000       2.00     10.000      0.00     10.000\n",
       "BFP        7211.000   11947.00   5391.000   3144.00  14162.000\n",
       "GF            5.000      89.00    557.000    321.00     56.000\n",
       "R           880.000    1129.00    568.000    312.00   1541.000\n",
       "SH           70.000       0.00     52.000     32.00    116.000\n",
       "SF           47.000       0.00     33.000     12.00     97.000\n",
       "GIDP        200.000       0.00     94.000     19.00    242.000\n",
       "yearID_y  22055.000   37145.00  38114.000  27720.00  45885.000\n",
       "ballots    5676.000    4769.00   9880.000   5390.00  10580.000\n",
       "needed     4257.000    3591.00   7410.000   4046.00   7935.000\n",
       "votes       143.000     456.00     57.000      0.00      0.000\n",
       "inducted      0.000       0.00      0.000      0.00      0.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pitchers.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_pitchers['inducted']\n",
    "X = data_pitchers.drop(['inducted'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's set aside a test set to evalute our models at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom transformer to drop features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features related to ballot voting results in order to prevent data leakage. Includes 'votes', 'needed', and 'ballots'.\n",
    "### Drop features that are not helpful due to aggregation, such as ERA and BAOpp (Averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def drop_features(df):\n",
    "    df = df.drop(['votes', 'needed', 'ballots', 'yearID_y', 'ERA', 'BAOpp', 'yearID_x'], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wins\n",
    "- Loss\n",
    "- Games\n",
    "- Games started\n",
    "- Complete Games\n",
    "- Shutouts\n",
    "- Saves\n",
    "- Outs Pitched\n",
    "- Hits\n",
    "- Earned Runs\n",
    "- Home runs\n",
    "- Walks\n",
    "- Strikeouts\n",
    "- Intentional Walks\n",
    "- Wild Pitches\n",
    "- Hit Batters\n",
    "- Balks\n",
    "- Batters faced by pitcher\n",
    "- Games finished\n",
    "- Runs allowed\n",
    "- Sacrifices by opposing batters\n",
    "- Sacrifice flies by opposing batters\n",
    "- Grounded into double plays by opposing batter\n",
    "- Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBB (Intentional Walks) , GIDP (Grounded Into Double Play), SF (Sacrifice Flys), HBP (Hit By Pitch), and SH (Sacrifice Bunts) were not recorded in the early days of baseball\n",
    "\n",
    "### Replace missing values with median value using ColumnTransformer and SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_tranf = ColumnTransformer([\n",
    "                                ('imp_cols', SimpleImputer(missing_values=0, strategy='median'), [23, 22, 21, 16, 14])\n",
    "                                ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent hall of famers in data = 17.56%\n",
      "Percent not hall of famers in data = 82.44%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percent hall of famers in data = {Counter(y)[1]/len(X) * 100:.2f}%')\n",
    "print(f'Percent not hall of famers in data = {Counter(y)[0]/len(X) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is imbalanced due to the Baseball hall of fame being an exclusive club\n",
    "#### Solution: Use smote to synthetically generate samples from minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics:\n",
    "1. F1-Weighted:\n",
    "    - Combines Recall (Fraction of True Postives to Actual Positives) and Precision (Fraction of True Positves to Predicted Positives)\n",
    "    - Good metric for imbalanced data\n",
    "2. Average Precision:\n",
    "    - Summarizes the precision-recall curve\n",
    "    - For reference: https://sanchom.wordpress.com/tag/average-precision/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup cv search across algorithms and hyperparameters to get best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class (provided by Brian in one of our class assignments)\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    \"Pass through class, methods are present but do nothing.\"\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup pipeline to cv search across algorthims\n",
    "pipe = Pipeline([('transformer', CustomTransformer(drop_features)),\n",
    "                ('col_transformer', column_tranf),\n",
    "                ('sm', SMOTE()),\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('clf', DummyEstimator())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's first select a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Randomized search to search across several different models and hyperparameters\n",
    "\n",
    "1. LogisticRegression\n",
    "    - penalty: pick what type of regularization we want to use\n",
    "    - class weight: probably good to include since we have imbalanaced imbalanced data\n",
    "    \n",
    "    \n",
    "2. RidgeClassifier\n",
    "    - alpha: represents strength of regularization\n",
    "    - class_weight: probably good to include since we have imbalanaced imbalanced data\n",
    " \n",
    " \n",
    "3. Lasso\n",
    "    - alpha:  represents strenght of L1 regularization\n",
    "    - Doesn't seem to have a class_weight hyperparameter, but does include feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=0.75)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = [\n",
    "                \n",
    "                {'clf': [LogisticRegression()],\n",
    "                 'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                 'clf__class_weight': [None, 'balanced']},\n",
    "               \n",
    "                {'clf': [RidgeClassifier()],\n",
    "                 'clf__alpha': [0.1, 0.5, 0.75],\n",
    "                 'clf__class_weight': [None, 'balanced']},\n",
    "\n",
    "                {'clf': [Lasso()],\n",
    "                 'clf__alpha': [0.1, 0.5, 0.75, 1]},\n",
    "    \n",
    "               ]\n",
    "\n",
    "clf_algos_rand = RandomizedSearchCV(estimator=pipe, \n",
    "                                    param_distributions=search_space, \n",
    "                                    n_iter=21,\n",
    "                                    cv=5, \n",
    "                                    n_jobs=-1,\n",
    "                                    scoring='f1_weighted',\n",
    "                                    verbose=1)\n",
    "\n",
    "# Grid search\n",
    "linear_model = clf_algos_rand.fit(X_train, y_train);\n",
    "\n",
    "# View best model\n",
    "linear_estimator = linear_model.best_estimator_.get_params()['clf']\n",
    "linear_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 <__main__.CustomTransformer object at 0x7fbdfdf5edc0>),\n",
       "                ('col_transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('imp_cols',\n",
       "                                                  SimpleImputer(missing_values=0,\n",
       "                                                                strategy='median'),\n",
       "                                                  [23, 22, 21, 16, 14])])),\n",
       "                ('sm', SMOTE()), ('scaler', MinMaxScaler()),\n",
       "                ('linear', RidgeClassifier(alpha=0.75))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_pipe = Pipeline([('transformer', CustomTransformer(drop_features)),\n",
    "                ('col_transformer', column_tranf),\n",
    "                ('sm', SMOTE()),\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('linear', linear_estimator)\n",
    "                ])\n",
    "linear_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try some ensemble models now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Use Randomized search to search across hyperparamers\n",
    "\n",
    "1. RandomForestClassifier\n",
    "2. ExtraTreesClassifier\n",
    "    - Criterion: \n",
    "        - Gini: measures how pure the class split is\n",
    "        - Entropy: measures information gain\n",
    "    - Max Depth:\n",
    "        - Puts a limit on the depth of the tree\n",
    "        - Stops trees from overfitting\n",
    "    - Min Samples Leaf:\n",
    "        - Limits leaves with few samples\n",
    "    - Class Weight:\n",
    "        - Could be useful to look at since we have unbalanced labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, max_features='sqrt', min_samples_leaf=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup pipeline to cv search across algorthims\n",
    "pipe = Pipeline([('transformer', CustomTransformer(drop_features)),\n",
    "                ('col_transformer', column_tranf),\n",
    "                ('sm', SMOTE()),\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('clf', DummyEstimator())\n",
    "                ])\n",
    "\n",
    "# Create search space of candidate algorthims and their hyperparameters\n",
    "# Search for optimal criterion, max_depth, min_samples\n",
    "search_space = [\n",
    "                \n",
    "                {'clf': [RandomForestClassifier()],\n",
    "                 'clf__criterion': ['gini', 'entropy'],\n",
    "                 'clf__max_depth': [None, 5, 10, 15, 20, 25],\n",
    "                 'clf__min_samples_leaf': [1, 3, 5, 10, 25, 100],\n",
    "                 'clf__max_features': ['auto', 'sqrt', 'log2']},\n",
    "    \n",
    "                {'clf': [ExtraTreesClassifier()],\n",
    "                 'clf__criterion': ['gini', 'entropy'],\n",
    "                 'clf__max_depth': [None, 5, 10, 15, 20, 25],\n",
    "                 'clf__min_samples_leaf': [1, 3, 5, 10, 25, 100],\n",
    "                 'clf__max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "                \n",
    "               ]\n",
    "clf_algos_rand = RandomizedSearchCV(estimator=pipe, \n",
    "                                    param_distributions=search_space, \n",
    "                                    n_iter=500,\n",
    "                                    cv=5, \n",
    "                                    n_jobs=-1,\n",
    "                                    scoring='f1_weighted',\n",
    "                                    verbose=1)\n",
    "\n",
    "# Grid search\n",
    "ensemble_model = clf_algos_rand.fit(X_train, y_train);\n",
    "\n",
    "ensemble_estimator = ensemble_model.best_estimator_.get_params()['clf']\n",
    "ensemble_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 <__main__.CustomTransformer object at 0x7fbdfe803910>),\n",
       "                ('col_transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('imp_cols',\n",
       "                                                  SimpleImputer(missing_values=0,\n",
       "                                                                strategy='median'),\n",
       "                                                  [23, 22, 21, 16, 14])])),\n",
       "                ('sm', SMOTE()), ('scaler', MinMaxScaler()),\n",
       "                ('linear',\n",
       "                 RandomForestClassifier(max_depth=20, max_features='sqrt',\n",
       "                                        min_samples_leaf=3))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_pipe = Pipeline([('transformer', CustomTransformer(drop_features)),\n",
    "                ('col_transformer', column_tranf),\n",
    "                ('sm', SMOTE()),\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('linear', ensemble_estimator)\n",
    "                ])\n",
    "ensemble_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use candidate models and compare cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average weighted f1 score for best linear model is 0.90\n",
      "Average weighted f1 score for best ensemble model is 0.88\n"
     ]
    }
   ],
   "source": [
    "linear_f1_cv_scores = cross_val_score(linear_pipe, X_train, y_train, scoring='f1_weighted', cv=5, verbose=False)\n",
    "ensemble_f1_cv_scores = cross_val_score(ensemble_pipe, X_train, y_train, scoring='f1_weighted', cv=5, verbose=False)\n",
    "print(f\"Average weighted f1 score for best linear model is {linear_f1_cv_scores.mean():.2f}\")\n",
    "print(f\"Average weighted f1 score for best ensemble model is {ensemble_f1_cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score for best linear model is 0.84\n",
      "Average precision score for best ensemble model is 0.76\n"
     ]
    }
   ],
   "source": [
    "linear_ap_cv_scores = cross_val_score(linear_pipe, X_train, y_train, scoring='average_precision', cv=5, verbose=False)\n",
    "ensemble_ap_cv_scores = cross_val_score(ensemble_pipe, X_train, y_train, scoring='average_precision', cv=5, verbose=False)\n",
    "print(f\"Average precision score for best linear model is {linear_ap_cv_scores.mean():.2f}\")\n",
    "print(f\"Average precision score for best ensemble model is {ensemble_ap_cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best linear model scores a little better than the ensemble model in both of the metrics\n",
    "\n",
    "#### Therefore the linear model will be selected as our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=0.75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final model parameters\n",
    "linear_pipe.named_steps['linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': <__main__.CustomTransformer at 0x7fbdfdf5edc0>,\n",
       " 'col_transformer': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('imp_cols',\n",
       "                                  SimpleImputer(missing_values=0,\n",
       "                                                strategy='median'),\n",
       "                                  [23, 22, 21, 16, 14])]),\n",
       " 'sm': SMOTE(),\n",
       " 'scaler': MinMaxScaler(),\n",
       " 'linear': RidgeClassifier(alpha=0.75)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full final pipeline\n",
    "linear_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Test Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipe.fit(X_train, y_train)\n",
    "final_model_preds = linear_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1\n",
       "0  63  5\n",
       "1   7  7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_true=y_test, y_pred=final_model_preds, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 score on the test set = 0.85\n",
      "Average precision score on the test set = 0.38\n",
      "Balanced accuracy on the test set = 0.71\n"
     ]
    }
   ],
   "source": [
    "print(f'Weighted f1 score on the test set = {f1_score(y_test, final_model_preds, average=\"weighted\"):.2f}')\n",
    "print(f'Average precision score on the test set = {average_precision_score(y_test, final_model_preds):.2f}')\n",
    "print(f'Balanced accuracy on the test set = {balanced_accuracy_score(y_test, final_model_preds):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
